{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Make json file </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read weather data\n",
    "weather_df = pd.read_csv('weather/addis_ababa__addis_ababa__addis_ketema__.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in all values as strings, or else the latitude, longitude precision gets truncated\n",
    "woreda_df = pd.read_csv('/Users/attiladobi/zen_staging/elevation_area/woreda_info.csv', dtype=str)\n",
    "#woreda_df.set_index('GeoKey', inplace=True)\n",
    "\n",
    "# Read in all values as strings or else the latitude, longitude double precision gets truncated\n",
    "#woreda_df = pd.read_csv('/Users/attiladobi/zen_staging/elevation_area/woreda_info.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Use woreda_mapped file </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_geo_code(name_list):\n",
    "    region, zone, woreda = name_list\n",
    "    return ('%s__%s__%s__' % (region, zone, woreda)).lower()\n",
    "\n",
    "def load_woreda_mapped(woreda_mapped_path):\n",
    "    # Load useing dtype=str to prevent truncating the double\n",
    "    woreda_df = pd.read_csv(woreda_mapped_path, dtype=str)\n",
    "    # Remove columns used for name matching\n",
    "    column_cut = [column for column in woreda_df.columns if 'match' not in column]\n",
    "    woreda_df = woreda_df[column_cut]\n",
    "    # Add GeoKey column\n",
    "    woreda_df['GeoKey'] = [get_geo_code(name_list) for name_list in woreda_df[['RegionName', 'ZoneName', 'WoredaName']].values]\n",
    "    return woreda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "woreda_mapped_path = '/Users/attiladobi/zenysis/pipeline/auto/ethiopia/bin/shared/data/woreda_mapped.csv'\n",
    "HEADERS = ['Real_Date', 'RegionName', 'ZoneName', 'WoredaName', 'WoredaLat', 'WoredaLon', 'source', 'field', 'val']\n",
    "FIELDS = ['precipitation', 'humid_max', 'humid_min', 'solar', 'temp_max', 'temp_min', 'wind_avg']\n",
    "\n",
    "FOLDER_PATH = 'weather'\n",
    "\n",
    "woreda_df = load_woreda_mapped(woreda_mapped_path)\n",
    "\n",
    "with gzip.open('weather.json.gz', 'wr') as f:\n",
    "    # loop through all of the Woreda weather data:\n",
    "    for filename in [csvfile for csvfile in listdir(FOLDER_PATH) if '.csv' in csvfile]:\n",
    "        # Load csv to dataframe\n",
    "        weather_df = pd.read_csv('%s/%s' % (FOLDER_PATH, filename), index_col=0)\n",
    "        # Inner join the two dataframes on the GeoKey\n",
    "        weather_merge = pd.merge(weather_df, woreda_df, how='inner', on='GeoKey')\n",
    "        \n",
    "        for row in weather_merge.iterrows():\n",
    "            row = row[1]\n",
    "            # Avoid pandas truncating the double\n",
    "            lat = float(row['WoredaLat'] )\n",
    "            lon = float(row['WoredaLon'] )\n",
    "            woreda_consts = row[['date', 'RegionName', 'ZoneName', 'WoredaName']].tolist() + [lat, lon, 'weather']\n",
    "            # Loop throgh all of the fields. Skip nan values.\n",
    "            for field, value in row[FIELDS].dropna().iteritems():\n",
    "                val_list = woreda_consts + [field, value]\n",
    "                # OderedDict to perserve header order\n",
    "                f.write(json.dumps( OrderedDict([(key, value) for key, value in zip(HEADERS, val_list)])))\n",
    "                f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
