{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create ET weater psql database  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from os import listdir\n",
    "from collections import OrderedDict\n",
    "from ethiopian_date import ethiopian_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> constants </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COLUMN_TYPES = OrderedDict([('date', 'date'), ('e_date', 'date'), ('GeoKey', 'text'), \\\n",
    "            ('precipitation', 'float'), ('humid_max', 'float'), ('humid_min', 'float'), ('solar', 'float'), \n",
    "            ('temp_max', 'float'), ('temp_min', 'float'), ('wind_avg', 'float')])\n",
    "\n",
    "KEYS = COLUMN_TYPES.keys()\n",
    "KEY_STR = ', '.join(KEYS)\n",
    "VAL_STR = ' ,'.join(['%s'] * len(KEYS))\n",
    "DATE_FORMAT = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_edate(date):\n",
    "    '''If 13th month we move forward 6 days to avoid error. The 13th month is lumped in with the 1st month'''\n",
    "    try:\n",
    "        return ethiopian_date.EthiopianDateConverter.date_to_ethiopian(date)\n",
    "    except ValueError:\n",
    "        return ethiopian_date.EthiopianDateConverter.date_to_ethiopian(date + pd.offsets.relativedelta(days=6))\n",
    "    \n",
    "def write_to_psql(row):\n",
    "    #insert into postgres\n",
    "    cur.execute('INSERT INTO daily ({:s}) VALUES ({:s})'.format(KEY_STR, VAL_STR), row[KEYS].values)\n",
    "    conn.commit() #submit change to db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Establish connections </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=localhost port=5432 dbname=et_weather user=attiladobi\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create new table for daily weather</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_str = ', '.join(['%s %s' % column for column in COLUMN_TYPES.items()])\n",
    "cur.execute('CREATE TABLE daily (id serial PRIMARY KEY, %s);' % column_str)\n",
    "conn.commit() #submit change to db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loop through all the woreda weather files and write to postgres db </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_dir = '/Users/attiladobi/PyNotebooks/zenysis/weather'\n",
    "for filename in [csvfile for csvfile in listdir(weather_dir) if '.csv' in csvfile]:\n",
    "    weather_df = pd.read_csv('%s/%s' % (weather_dir, filename), index_col=0)\n",
    "    weather_df['e_date'] = [make_edate(date).strftime(DATE_FORMAT) for date in pd.to_datetime(weather_df['date'])]\n",
    "    # Write NaN as NULL in postgres to avoid issues with aggregation\n",
    "    weather_df = weather_df.where(pd.notnull(weather_df), None)\n",
    "    # Loop through each row writing to postgres\n",
    "    for row in weather_df.iterrows():\n",
    "        write_to_psql(row[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create a new monthly table </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# runs in about 10s\n",
    "create_mothly_str = \\\n",
    "\"CREATE TABLE monthly AS \\\n",
    "SELECT date_trunc('month', e_date) AS e_date, \\\n",
    "geokey, \\\n",
    "SUM(precipitation) as precipitation, \\\n",
    "MAX(precipitation) as max_precipitation, \\\n",
    "SUM(CASE WHEN precipitation = 0 THEN 0 ELSE 1 END) as days_precipitation, \\\n",
    "AVG(wind_avg) as wind_avg, \\\n",
    "MAX(temp_max) as temp_max, \\\n",
    "MIN(temp_min) as temp_min, \\\n",
    "AVG((temp_min + temp_max)/2) as temp_avg, \\\n",
    "MAX(humid_max) as humid_max, \\\n",
    "MIN(humid_min) as humid_min, \\\n",
    "AVG((humid_max + humid_min)/2) as humid_avg, \\\n",
    "AVG(solar) as solar \\\n",
    "from daily group by (geokey, 1);\"\n",
    "\n",
    "cur.execute(create_mothly_str)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Add functions to take updates, tack on to the daily db and update momthly table </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
