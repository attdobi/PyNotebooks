{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from __future__ import division\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "import re\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost port=5432 dbname=amazon user=postgres password=darkmatter\")\n",
    "cur = conn.cursor()\n",
    "#connect to db and find q/a\n",
    "cur.execute(\"SELECT question from qa;\")\n",
    "Qresults=cur.fetchall()\n",
    "cur.execute(\"SELECT answer from qa;\")\n",
    "Aresults=cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'yes/no';\")\n",
    "Q_yn=cur.fetchall()\n",
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'open-ended';\")\n",
    "Q_oe=cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_line(sentence):\n",
    "    #step 1 split if we need to\n",
    "    sentences=re.split(r'[;:!?.-]\\s*', sentence)\n",
    "    result= [re.findall(\"[a-z']+\", sent.lower()) for sent in sentences if \\\n",
    "            re.findall(\"[a-z']+\", sent.lower())!=[]]\n",
    "    if result==[]:\n",
    "        result=['']\n",
    "    return result\n",
    "stoplist = set('for a of the and to in rt'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Clean up the sentence </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qs_yn= [[word for word in process_line(sentence[0])[0] if word not in stoplist] for sentence in Q_yn]\n",
    "qs_yn_sample=qs_yn[:int(len(qs_yn)/2)]\n",
    "qs_oe= [[word for word in process_line(sentence[0])[0] if word not in stoplist] for sentence in Q_oe]\n",
    "qs_oe_sample=qs_oe[:int(len(qs_oe)/2)]\n",
    "\n",
    "#here we only extract the first sentence for training. Only use 1/2 of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> build labeled docs </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeledSent = [LabeledSentence(words= word[:5], tags=['YN_'+str(ii)]) for ii,word in enumerate(qs_yn_sample)]+\\\n",
    "    [LabeledSentence(words= word[:5], tags=['OE_'+str(ii)]) for ii,word in enumerate(qs_oe_sample)]\n",
    "    \n",
    "#only using first 4 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9799914"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Doc2Vec(min_count=4, window=10, size=100, sample=1e-4, negative=5, workers=4)\n",
    "model.build_vocab(labeledSent)\n",
    "model.train(labeledSent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Setup Training </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_yn_arrays = np.zeros((len(qs_yn_sample), 100))\n",
    "all_oe_arrays = np.zeros((len(qs_oe_sample), 100))\n",
    "all_yn_labels = np.zeros(len(qs_yn_sample))\n",
    "all_oe_labels = np.zeros(len(qs_oe_sample))\n",
    "\n",
    "#setup training for Y/N questions\n",
    "for i in range(len(qs_yn_sample)):\n",
    "    all_yn_arrays[i] = model.docvecs[i]\n",
    "    all_yn_labels[i] = 1\n",
    "\n",
    "#setup training for open-ended questions\n",
    "for ii in range(len(qs_oe_sample)):\n",
    "    all_oe_arrays[ii] = model.docvecs[i+ii]\n",
    "    all_oe_labels[ii] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Setup Testing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nyn=len(all_yn_arrays)\n",
    "Noe=len(all_oe_arrays)\n",
    "\n",
    "train_arrays = np.vstack((all_yn_arrays[:Nyn/2],all_oe_arrays[:Noe/2]))\n",
    "train_labels = np.hstack((all_yn_labels[:Nyn/2],all_oe_labels[:Noe/2]))\n",
    "\n",
    "test_arrays = np.vstack((all_yn_arrays[Nyn/2:],all_oe_arrays[Noe/2:]))\n",
    "test_labels = np.hstack((all_yn_labels[Nyn/2:],all_oe_labels[Noe/2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> logistic regresion </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62981293082684342"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Random Forest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier =RandomForestClassifier()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61770335271220578"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test on data not used in traning </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "prediction=[classifier.predict(model.infer_vector(line_arr)) for line_arr in qs_yn[-2000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5915])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction)/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_oe=[classifier.predict(model.infer_vector(line_arr)) for line_arr in qs_oe[-2000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4695])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([val==0 for val in prediction_oe])/len(prediction_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> user input </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_arr=\"do I need to\".split()\n",
    "classifier.predict(model.infer_vector(lin_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
