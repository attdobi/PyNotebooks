{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import json\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> connect to postgres db and pull quesiton and answer text</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=localhost port=5432 dbname=amazon user=postgres password=darkmatter\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa;\")\n",
    "Qresults=cur.fetchall()\n",
    "cur.execute(\"SELECT answer from qa;\")\n",
    "Aresults=cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> clean up each question/answer and tokenize </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def process_line(sentence):\n",
    "#    filter_text=' '.join(re.findall(\"[a-z'?]+\", sentence.lower()))\n",
    "#    #return nltk.word_tokenize(filter_text)\n",
    "#    return filter_text.replace('?',' ? ').split()\n",
    "def process_line(sentence):\n",
    "    #step 1 split if we need to\n",
    "    sentences=re.split(r'[;:!?.-]\\s*', sentence)\n",
    "    result= [re.findall(\"[a-z']+\", sent.lower()) for sent in sentences if \\\n",
    "            re.findall(\"[a-z']+\", sent.lower())!=[]]\n",
    "    if result==[]:\n",
    "        result=[['']]\n",
    "    return result\n",
    "stoplist = set('for a of the and to in rt'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> define stop words and apply </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_sentence= [[word for word in sum(process_line(sentence[0]),[]) if word not in stoplist] for sentence in Aresults]\n",
    "#get the entire answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train word2Vec model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Qmodel = models.Word2Vec(answer_sentence, size=100, window=5, min_count=10, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('or', 0.6198657751083374),\n",
       " ('also', 0.6104353070259094),\n",
       " ('ie', 0.47483423352241516),\n",
       " ('it', 0.44304147362709045),\n",
       " ('this', 0.43430107831954956),\n",
       " ('that', 0.4327320456504822),\n",
       " ('meaning', 0.42874017357826233),\n",
       " ('does', 0.4074341654777527),\n",
       " ('thanks', 0.4056839942932129),\n",
       " ('with', 0.4022674560546875)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qmodel.most_similar('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train biagram </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Abigram = models.Phrases(answer_sentence,min_count=5) #model bigrams\n",
    "Abigrams=list(Abigram[answer_sentence]) #make list\n",
    "AmodelB = models.Word2Vec(Abigrams, size=100, window=5, min_count=5, workers=8) #train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"doesn't\", 0.7825628519058228),\n",
       " ('doesnt', 0.6989734172821045),\n",
       " ('did', 0.6647682189941406),\n",
       " ('dose', 0.5925465226173401),\n",
       " ('will', 0.5911905765533447),\n",
       " (\"dosen't\", 0.5073017477989197),\n",
       " ('tends', 0.5064404606819153),\n",
       " ('do', 0.4974463880062103),\n",
       " (\"didn't\", 0.4885160028934479),\n",
       " ('dosent', 0.48564204573631287)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AmodelB.most_similar('does') #positive=['finna', 'gonna'], negative=['bro'],topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AmodelB.save('/home/ubuntu/TallLabs/models/AmodelB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Train Doc2vec </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lb_sentence:\n",
    "    def __init__(self, sentence_list,tag):\n",
    "        self.words=sentence_list\n",
    "        self.tags=tag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lb_qs=LabeledSentence(question_sentence,1)\n",
    "lb_qs=[lb_sentence(sen ,np.ones(len(sen)))for sen in question_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.Doc2Vec(lb_qs, size=100, window=8, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model =  models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "model.build_vocab(lb_qs)\n",
    "for epoch in range(10):\n",
    "    model.train(lb_qs)\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recharger', 0.7499253153800964),\n",
       " ('chargeable', 0.632102906703949),\n",
       " ('rechargeable', 0.6074789762496948),\n",
       " ('lithium', 0.5788451433181763),\n",
       " ('chargable', 0.5748066902160645),\n",
       " ('lithiom', 0.5646908283233643),\n",
       " ('rechargable', 0.5600529313087463),\n",
       " ('gpa', 0.5514222383499146),\n",
       " ('toothbrush', 0.5457131266593933),\n",
       " ('nicad', 0.5350093245506287)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('charger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lda2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
