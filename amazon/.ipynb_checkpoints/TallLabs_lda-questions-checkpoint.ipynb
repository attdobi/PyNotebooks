{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test of modeling question topics </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "#from sklearn.datasets import fetch_20newsgroups\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "#import stopwords\n",
    "#from pattern.en import lemma\n",
    "import re\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> connect to postgres db and pull quesiton and answer text</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost port=5432 dbname=amazon user=postgres password=darkmatter\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa;\")\n",
    "Qresults=cur.fetchall()\n",
    "cur.execute(\"SELECT answer from qa;\")\n",
    "Aresults=cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> clean up each question/answer and tokenize </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_line(sentence):\n",
    "    #step 1 split if we need to\n",
    "    sentences=re.split(r'[;:!?.-]\\s*', sentence)\n",
    "    result= [re.findall(\"[a-z'1-9]+\", sent.lower()) for sent in sentences if \\\n",
    "            re.findall(\"[a-z'1-9]+\", sent.lower())!=[]]\n",
    "    if result==[]:\n",
    "        result=[['']]\n",
    "    return result\n",
    "stoplist = set('for a of the and to in rt'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sentence =\"this doesn't work so well ?   why\"\n",
    "#filter_text=' '.join(re.findall(\"[a-z'?]+\", sentence.lower()))\n",
    "#filter_text.replace('?',' ? ').split()\n",
    "#nltk.word_tokenize(filter_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> define stop words to remove from the question model and apply </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'and', 'for', 'in', 'of', 'rt', 'the', 'to'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = set('a for of the and to in rt'.split())\n",
    "stoplist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Use word2vec trained on the question model to remove the irrelavent words from the topic </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#QmodelB=models.Word2Vec.load('/home/ubuntu/TallLabs/models/QmodelB')\n",
    "bag_of_words='is,will,wil,may,might,does,do,can,could,must,should,are,would,did,need,take,out,how,would,\\\n",
    "anyone,has,have,off,that,which,who,please,thank,you,that,fit,these,they,many,work,with,time,turn,\\\n",
    "from,hard,use,your,not,into,non,hold,say,from,with,one,two,like,than,same,\\\n",
    "son,daughter,amazon,when,after,change,both'.split(',')\n",
    "complete_bag=set(sum([[item[0] for item in QmodelB.most_similar(word)] for word in bag_of_words],[]))|stoplist|set(bag_of_words)\n",
    "#complete_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_sentence= [[word for word in sum(process_line(sentence[0]),[]) if word not in complete_bag] for sentence in Qresults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lense', 'be', 'used', 'nikon']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_sentence[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train LDA model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_savepath='/home/ubuntu/amazon/gensQuestions.mm'\n",
    "\n",
    "texts = question_sentence\n",
    "#texts = [\"\".join((char if char.isalpha() else \" \") for char in text).split() for text in texts]\n",
    "#texts = [stopwords.clean([lemma(i) for i in text[:1000]], \"en\") for text in texts]\n",
    "\n",
    "#creating frequency dictionary for tokens in text\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "#removing very infrequent and very frequent tokens in corpus\n",
    "texts = [[token for token in text if (frequency[token] > 10 and len(token) > 2 and frequency[token] < len(texts)*0.2)] for text in texts]\n",
    "\n",
    "#creating an LDA model\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "gensim.corpora.MmCorpus.serialize(corpus_savepath, corpus)\n",
    "modelled_corpus = gensim.corpora.MmCorpus(corpus_savepath)\n",
    "\n",
    "#will use the multicor version below\n",
    "\n",
    "#lda = gensim.models.ldamodel.LdaModel(modelled_corpus, num_topics=20, update_every=100, passes=20,\\\n",
    "#                                      id2word=dictionary, alpha='auto', eval_every=5)\n",
    "\n",
    "#returning the resulting topics\n",
    "#lda.show_topics(num_topics=20, num_words=10, formatted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_savepath='/home/ubuntu/amazon/gensQuestions.mm'\n",
    "modelled_corpus = gensim.corpora.MmCorpus(corpus_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.074*buy + 0.049*set + 0.033*come + 0.031*part + 0.028*purchase + 0.026*replacement + 0.023*replace + 0.021*include + 0.020*handle + 0.018*just'),\n",
       " (1,\n",
       "  '0.037*lens + 0.030*windows + 0.028*material + 0.025*system + 0.022*safe + 0.020*canon + 0.019*fan + 0.017*attach + 0.017*paper + 0.016*body'),\n",
       " (2,\n",
       "  '0.053*make + 0.044*hair + 0.027*mount + 0.027*sure + 0.026*machine + 0.024*original + 0.021*wall + 0.015*come + 0.014*socks + 0.013*used'),\n",
       " (3,\n",
       "  \"0.044*why + 0.041*item + 0.039*weight + 0.037*difference + 0.022*free + 0.022*shipping + 0.022*price + 0.021*product + 0.019*what's + 0.016*package\"),\n",
       " (4,\n",
       "  '0.049*much + 0.046*dimensions + 0.045*inside + 0.032*amp + 0.019*clean + 0.018*head + 0.018*outside + 0.016*speaker + 0.016*weigh + 0.015*manual'),\n",
       " (5,\n",
       "  '0.032*screen + 0.032*type + 0.027*camera + 0.026*sizes + 0.019*pants + 0.019*belt + 0.015*clip + 0.014*ford + 0.013*computer + 0.013*drive'),\n",
       " (6,\n",
       "  '0.121*case + 0.054*well + 0.052*old + 0.052*cover + 0.033*inch + 0.031*year + 0.030*version + 0.028*warranty + 0.019*come + 0.015*pro'),\n",
       " (7,\n",
       "  '0.040*unit + 0.038*power + 0.033*plug + 0.028*batteries + 0.023*connect + 0.023*cord + 0.022*device + 0.022*usb + 0.021*cable + 0.020*adapter'),\n",
       " (8,\n",
       "  '0.220*size + 0.047*small + 0.039*large + 0.028*order + 0.024*medium + 0.023*kit + 0.023*wide + 0.022*lbs + 0.021*filter + 0.020*get'),\n",
       " (9,\n",
       "  '0.091*good + 0.061*compatible + 0.048*card + 0.036*play + 0.034*sim + 0.023*game + 0.019*honda + 0.014*cards + 0.014*ingredients + 0.013*board'),\n",
       " (10,\n",
       "  '0.110*there + 0.093*any + 0.027*way + 0.017*about + 0.015*bed + 0.014*pump + 0.013*get + 0.013*full + 0.012*else + 0.012*problem'),\n",
       " (11,\n",
       "  '0.054*iphone + 0.050*box + 0.027*just + 0.019*mini + 0.018*bought + 0.018*pair + 0.017*now + 0.016*ipad + 0.016*button + 0.014*instructions'),\n",
       " (12,\n",
       "  '0.086*product + 0.033*tell + 0.031*inches + 0.029*length + 0.027*description + 0.025*comes + 0.025*height + 0.023*thanks + 0.021*see + 0.017*width'),\n",
       " (13,\n",
       "  '0.144*phone + 0.061*model + 0.060*made + 0.036*galaxy + 0.034*plastic + 0.034*samsung + 0.018*metal + 0.016*glass + 0.015*unlocked + 0.015*remote'),\n",
       " (14,\n",
       "  '0.058*water + 0.052*top + 0.045*side + 0.033*bottom + 0.025*bottle + 0.023*base + 0.017*feet + 0.016*end + 0.015*hole + 0.013*holes'),\n",
       " (15,\n",
       "  '0.055*color + 0.036*black + 0.032*picture + 0.030*different + 0.028*white + 0.019*looks + 0.019*look + 0.018*red + 0.017*blue + 0.017*cut'),\n",
       " (16,\n",
       "  '0.054*car + 0.051*seat + 0.025*stand + 0.021*sound + 0.019*piece + 0.018*bar + 0.014*chair + 0.014*dog + 0.013*floor + 0.013*space'),\n",
       " (17,\n",
       "  \"0.042*i'm + 0.034*looking + 0.032*wear + 0.028*bag + 0.019*keep + 0.017*shoe + 0.016*something + 0.012*hot + 0.012*sizing + 0.012*left\"),\n",
       " (18,\n",
       "  '0.055*light + 0.035*big + 0.023*door + 0.020*tall + 0.020*run + 0.018*lights + 0.015*table + 0.014*switch + 0.013*high + 0.013*oil'),\n",
       " (19,\n",
       "  '0.101*long + 0.080*battery + 0.034*charge + 0.032*charger + 0.025*pack + 0.023*last + 0.014*air + 0.014*come + 0.014*mattress + 0.013*support')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = gensim.models.ldamulticore.LdaMulticore(modelled_corpus, num_topics=20, workers=8, iterations=20, passes=20,\\\n",
    "                                      id2word=dictionary, eval_every=5)\n",
    "\n",
    "#returning the resulting topics\n",
    "lda.show_topics(num_topics=20, num_words=10, formatted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11,\n",
       "  '0.054*iphone + 0.050*box + 0.027*just + 0.019*mini + 0.018*bought + 0.018*pair + 0.017*now + 0.016*ipad + 0.016*button + 0.014*instructions'),\n",
       " (17,\n",
       "  \"0.042*i'm + 0.034*looking + 0.032*wear + 0.028*bag + 0.019*keep + 0.017*shoe + 0.016*something + 0.012*hot + 0.012*sizing + 0.012*left\"),\n",
       " (0,\n",
       "  '0.074*buy + 0.049*set + 0.033*come + 0.031*part + 0.028*purchase + 0.026*replacement + 0.023*replace + 0.021*include + 0.020*handle + 0.018*just'),\n",
       " (16,\n",
       "  '0.054*car + 0.051*seat + 0.025*stand + 0.021*sound + 0.019*piece + 0.018*bar + 0.014*chair + 0.014*dog + 0.013*floor + 0.013*space'),\n",
       " (7,\n",
       "  '0.040*unit + 0.038*power + 0.033*plug + 0.028*batteries + 0.023*connect + 0.023*cord + 0.022*device + 0.022*usb + 0.021*cable + 0.020*adapter'),\n",
       " (10,\n",
       "  '0.110*there + 0.093*any + 0.027*way + 0.017*about + 0.015*bed + 0.014*pump + 0.013*get + 0.013*full + 0.012*else + 0.012*problem'),\n",
       " (13,\n",
       "  '0.144*phone + 0.061*model + 0.060*made + 0.036*galaxy + 0.034*plastic + 0.034*samsung + 0.018*metal + 0.016*glass + 0.015*unlocked + 0.015*remote'),\n",
       " (8,\n",
       "  '0.220*size + 0.047*small + 0.039*large + 0.028*order + 0.024*medium + 0.023*kit + 0.023*wide + 0.022*lbs + 0.021*filter + 0.020*get'),\n",
       " (18,\n",
       "  '0.055*light + 0.035*big + 0.023*door + 0.020*tall + 0.020*run + 0.018*lights + 0.015*table + 0.014*switch + 0.013*high + 0.013*oil'),\n",
       " (1,\n",
       "  '0.037*lens + 0.030*windows + 0.028*material + 0.025*system + 0.022*safe + 0.020*canon + 0.019*fan + 0.017*attach + 0.017*paper + 0.016*body')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics(num_topics=10, num_words=10, formatted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> vectorize words </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id2word_ans = gensim.corpora.Dictionary(question_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ignore words that appear in less than 20 documents or more than 10% documents\n",
    "id2word_ans.filter_extremes(no_below=100, no_above=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_vector = id2word_ans.doc2bow(['iphone','charger','battery'])\n",
    "bow_vector = id2word_ans.doc2bow(['nikon','camera','lense','photo'])\n",
    "\n",
    "# transform into LDA space\n",
    "lda_vector = lda[bow_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.121*case + 0.054*well + 0.052*old + 0.052*cover + 0.033*inch + 0.031*year + 0.030*version + 0.028*warranty + 0.019*come + 0.015*pro\n"
     ]
    }
   ],
   "source": [
    "# print the document's single most prominent LDA topic\n",
    "print(lda.print_topic(max(lda_vector, key=lambda item: item[1])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
