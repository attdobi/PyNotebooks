{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import json\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> connect to postgres db and pull quesiton and answer text</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=localhost port=5432 dbname=amazon user=postgres password=darkmatter\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa;\")\n",
    "Qresults=cur.fetchall()\n",
    "cur.execute(\"SELECT answer from qa;\")\n",
    "Aresults=cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> clean up each question/answer and tokenize </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_line(sentence):\n",
    "    #step 1 split if we need to\n",
    "    sentences=re.split(r\"(?<![0-9])[.?!;](?![0-9])\", sentence)\n",
    "    result= [re.findall(\"[a-z'.-0-9]+\", sent.lower()) for sent in sentences if \\\n",
    "            re.findall(\"[a-z'.-0-9]+\", sent.lower())!=[]]\n",
    "    if result==[]:\n",
    "        result=[['']]\n",
    "    return result\n",
    "stoplist = set('for a of the and to in rt'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sentence =\"this doesn't work so well ?   why\"\n",
    "#filter_text=' '.join(re.findall(\"[a-z'?]+\", sentence.lower()))\n",
    "#filter_text.replace('?',' ? ').split()\n",
    "#nltk.word_tokenize(filter_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> define stop words and apply </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'for', 'in', 'of', 'rt', 'the', 'to'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = set('for of the and to in rt'.split())\n",
    "stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_sentence= [[word for word in sum(process_line(sentence[0]),[]) if word not in stoplist] for sentence in Qresults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'this',\n",
       " 'badger',\n",
       " 'compatible',\n",
       " 'with',\n",
       " 'badger',\n",
       " 'model',\n",
       " '?',\n",
       " 'same',\n",
       " 'size',\n",
       " 'fittings',\n",
       " '?']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_sentence[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train word2Vec model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Qmodel = models.Word2Vec(question_sentence, size=100, window=5, min_count=10, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('or', 0.6198657751083374),\n",
       " ('also', 0.6104353070259094),\n",
       " ('ie', 0.47483423352241516),\n",
       " ('it', 0.44304147362709045),\n",
       " ('this', 0.43430107831954956),\n",
       " ('that', 0.4327320456504822),\n",
       " ('meaning', 0.42874017357826233),\n",
       " ('does', 0.4074341654777527),\n",
       " ('thanks', 0.4056839942932129),\n",
       " ('with', 0.4022674560546875)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qmodel.most_similar('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train biagram </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Qbigram = models.Phrases(question_sentence,min_count=5) #model bigrams\n",
    "Qbigrams=list(Qbigram[question_sentence]) #make list\n",
    "QmodelB = models.Word2Vec(Qbigrams, size=100, window=5, min_count=5, workers=8) #train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dose', 0.8526506423950195),\n",
       " ('doe', 0.7331932783126831),\n",
       " (\"doesn't\", 0.6430281400680542),\n",
       " ('will', 0.6202369928359985),\n",
       " ('dos', 0.6173581480979919),\n",
       " ('doesnt', 0.5512901544570923),\n",
       " ('did', 0.5015972852706909),\n",
       " (\"doesn_'t\", 0.4602945148944855),\n",
       " ('ability', 0.4364972710609436),\n",
       " (\"won't\", 0.4283829927444458)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QmodelB.most_similar('does') #positive=['finna', 'gonna'], negative=['bro'],topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QmodelB.save('/home/ubuntu/TallLabs/models/QmodelB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1> Train Doc2vec </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lb_sentence:\n",
    "    def __init__(self, sentence_list,tag):\n",
    "        self.words=sentence_list\n",
    "        self.tags=tag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lb_qs=LabeledSentence(question_sentence,1)\n",
    "lb_qs=[lb_sentence(sen ,np.ones(len(sen)))for sen in question_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.Doc2Vec(lb_qs, size=100, window=8, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model =  models.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
    "model.build_vocab(lb_qs)\n",
    "for epoch in range(10):\n",
    "    model.train(lb_qs)\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recharger', 0.7499253153800964),\n",
       " ('chargeable', 0.632102906703949),\n",
       " ('rechargeable', 0.6074789762496948),\n",
       " ('lithium', 0.5788451433181763),\n",
       " ('chargable', 0.5748066902160645),\n",
       " ('lithiom', 0.5646908283233643),\n",
       " ('rechargable', 0.5600529313087463),\n",
       " ('gpa', 0.5514222383499146),\n",
       " ('toothbrush', 0.5457131266593933),\n",
       " ('nicad', 0.5350093245506287)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('charger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lda2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
