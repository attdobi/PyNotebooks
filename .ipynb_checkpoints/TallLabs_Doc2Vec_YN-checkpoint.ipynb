{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Learn Yes/No type with genSIM and random forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from __future__ import division\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "import re\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost port=5432 dbname=qa\")\n",
    "cur = conn.cursor()\n",
    "#connect to db and find q/a\n",
    "cur.execute(\"SELECT question from qa;\")\n",
    "Qresults=cur.fetchall()\n",
    "cur.execute(\"SELECT answer from qa;\")\n",
    "Aresults=cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> load in yes/no question </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'yes/no';\")\n",
    "Q_yn=cur.fetchall()\n",
    "#Q_yn_sample=Q_yn[:int(len(Q_yn)/4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> load in open-ended </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'open-ended';\")\n",
    "Q_oe=cur.fetchall()\n",
    "#Q_oe_sample=Q_yn[:int(len(Q_oe)/4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> clean up sentences </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_line(sentence):\n",
    "    filter_text=' '.join(re.findall(\"[a-z']+\", sentence.lower())) #removed ?\n",
    "    #return nltk.word_tokenize(filter_text)\n",
    "    return filter_text.replace('?',' ? ').split()\n",
    "\n",
    "stoplist = set('for a of the and to in rt'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_yn= [[word for word in process_line(sentence[0]) if word not in stoplist] for sentence in Q_yn \\\n",
    "        if len(sentence[0].split())<8 ]\n",
    "qs_yn_sample=qs_yn[:int(len(qs_yn)/5)]\n",
    "\n",
    "qs_oe= [[word for word in process_line(sentence[0]) if word not in stoplist] for sentence in Q_oe\\\n",
    "       if len(sentence[0].split())<8]\n",
    "qs_oe_sample=qs_oe[:int(len(qs_oe)/5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> build labeled sentences for two catagories. Using 1/10 of the q/a data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lb_qs=LabeledSentence(question_sentence,1)\n",
    "#sentences=[LabeledSentence(sen ,['YN_'+str(ii)]) for ii,sen in enumerate(qs_yn_sample)] + \\\n",
    "#[LabeledSentence(sen ,['ON_'+str(ii)]) for sen in enumerate(qs_oe_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeledSent = [TaggedDocument(words= word, tags=['YN_'+str(ii)]) for ii,word in enumerate(qs_yn_sample)]+\\\n",
    "    [TaggedDocument(words= word, tags=['OE_'+str(ii)]) for ii,word in enumerate(qs_oe_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['will', 'it', 'fit', 'fn', 'mk'],\n",
       " ['is', 'there', 'pressure', 'switch', 'this'],\n",
       " ['does', 'this', 'wristband', 'work', 'with', 'fitbit', 'one'],\n",
       " ['do', 'these', 'clasps', 'contain', 'nickel'],\n",
       " ['can', 'ropes', 'be', 'replaced', 'out'],\n",
       " ['are', 'there', 'other', 'colors', 'available'],\n",
       " ['will', 'it', 'count', 'exercise', 'bicycle', 'pedaling'],\n",
       " ['does', 'it', 'calculate', 'walking', 'up', 'steps'],\n",
       " ['does', 'it', 'come', 'with', 'leash'],\n",
       " ['is', 'there', 'warranty'],\n",
       " ['does', 'it', 'include', 'an', 'instruction', 'manual'],\n",
       " ['will', 'it', 'work', 'on', 'savage', 'r'],\n",
       " ['will', 'it', 'work', 'on', 'mm', 'carbine'],\n",
       " ['can', 'i', 'sync', 'this', 'with', 'myfitnesspal'],\n",
       " ['can', 'you', 'play', 'music'],\n",
       " ['can', 'i', 'swim', 'with', 'this', 'product'],\n",
       " ['does', 'it', 'come', 'with', 'stickers', 'inside'],\n",
       " ['will', 'this', 'hold', 'all', 'stickers'],\n",
       " ['can', 'you', 'put', 'carbonated', 'beverages', 'it'],\n",
       " ['does', 'this', 'bottle', 'have', 'straw']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_yn_sample[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"what's\", \"short's\", 'inseam'],\n",
       " ['okay', 'swimming'],\n",
       " [\"what's\", \"short's\", 'inseam'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['dos', 'it', 'get', 'any', 'wheelbite'],\n",
       " ['what', 'color', 'is', 'petrol'],\n",
       " ['how', 'should', 'i', 'select', 'size'],\n",
       " ['who', 'is', 'manufacturer'],\n",
       " ['how', 'should', 'i', 'select', 'size'],\n",
       " ['who', 'is', 'manufacturer'],\n",
       " ['how', 'should', 'i', 'select', 'size'],\n",
       " ['who', 'is', 'manufacturer'],\n",
       " ['what', 'is', 'material', 'this', 'hoodie'],\n",
       " ['why', \"don't\", 'you', 'ship', 'canada']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_oe_sample[-100:-80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105658"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Doc2Vec(min_count=2, window=10, size=100, sample=1e-4, negative=5, workers=4)\n",
    "model.build_vocab(labeledSent)\n",
    "model.train(labeledSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=2, window=10, size=100, sample=1e-4, negative=5, workers=4)\n",
    "model.build_vocab(labeledSent)\n",
    "model.train(labeledSent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> find the nearest vector given a document </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09304538, -0.06521899,  0.04634081,  0.02697056, -0.20270567,\n",
       "       -0.07130437, -0.14846732,  0.06958241,  0.1527783 , -0.19649601,\n",
       "       -0.06851415, -0.04227942, -0.00445686, -0.08163343,  0.0993698 ,\n",
       "        0.16450356,  0.01251123, -0.11030179,  0.12296146,  0.04138965,\n",
       "       -0.12058368,  0.03205103,  0.08946534,  0.00786086, -0.03895753,\n",
       "        0.05506664, -0.0404918 , -0.00634865, -0.09605183,  0.06168461,\n",
       "       -0.16528313, -0.00939461, -0.21278271, -0.25120962,  0.02114294,\n",
       "       -0.05449814, -0.17052536,  0.01130025, -0.0417892 ,  0.08183662,\n",
       "       -0.19113393,  0.07282624, -0.14438581,  0.04783099, -0.08380287,\n",
       "       -0.14739044,  0.10820132,  0.24149573,  0.01421128, -0.12290509,\n",
       "       -0.21093376, -0.08331841,  0.03711683,  0.03967838,  0.03124719,\n",
       "       -0.12439016, -0.04529783, -0.09379324, -0.18731308,  0.06346867,\n",
       "        0.06549236, -0.04709509, -0.2600368 , -0.03634615,  0.01199164,\n",
       "       -0.16844882,  0.1537087 , -0.25470427,  0.06948453,  0.04463887,\n",
       "       -0.05328673, -0.08168495,  0.00061685,  0.11212715, -0.02707002,\n",
       "       -0.23435695, -0.10797992, -0.04740754,  0.02707382, -0.06032944,\n",
       "        0.20946139, -0.045451  , -0.28476268,  0.17744341, -0.04379719,\n",
       "        0.11366775,  0.10143272, -0.00506146,  0.07147441,  0.16524771,\n",
       "        0.12767416,  0.27850926,  0.08315558, -0.02073407, -0.24684741,\n",
       "        0.01393649,  0.28168276, -0.10481501,  0.08167847,  0.10817504], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['can','I','eat','this'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.most_similar('battery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Setup training (all used in model traning) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model was trained on labeledSent with qs_yn_sample + qs_oe_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yn_arrays = np.zeros((len(qs_yn_sample), 100))\n",
    "all_oe_arrays = np.zeros((len(qs_oe_sample), 100))\n",
    "all_yn_labels = np.zeros(len(qs_yn_sample))\n",
    "all_oe_labels = np.zeros(len(qs_oe_sample))\n",
    "\n",
    "#setup training for Y/N questions\n",
    "for i in range(len(qs_yn_sample)):\n",
    "    all_yn_arrays[i] = model.docvecs[i]\n",
    "    all_yn_labels[i] = 1\n",
    "\n",
    "#setup training for open-ended questions\n",
    "for ii in range(len(qs_oe_sample)):\n",
    "    all_oe_arrays[ii] = model.docvecs[i+ii]\n",
    "    all_oe_labels[ii] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Setup testing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nyn=len(all_yn_arrays)\n",
    "Noe=len(all_oe_arrays)\n",
    "\n",
    "train_arrays = np.vstack((all_yn_arrays[:Nyn/2],all_oe_arrays[:Noe/2]))\n",
    "train_labels = np.hstack((all_yn_labels[:Nyn/2],all_oe_labels[:Noe/2]))\n",
    "\n",
    "test_arrays = np.vstack((all_yn_arrays[Nyn/2:],all_oe_arrays[Noe/2:]))\n",
    "test_labels = np.hstack((all_yn_labels[Nyn/2:],all_oe_labels[Noe/2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Logistic Regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57739743924745235"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> try others </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train_arrays, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#knn.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Linear </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64404762758155976"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/attiladobi/anaconda2/lib/python2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearRegression()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097104787345749566"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test against real YN questions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "prediction=[classifier.predict(model.infer_vector(line_arr)) for line_arr in qs_yn[-1000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([val==1 for val in prediction])/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_oe=[classifier.predict(model.infer_vector(line_arr)) for line_arr in qs_oe[-1000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.486])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([val==0 for val in prediction_oe])/len(prediction_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52009877])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_arr=\"do i need one or two\".split()\n",
    "classifier.predict(model.infer_vector(lin_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Random Forest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier =RandomForest()\n",
    "classifier.fit(train_arrays, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.081006003452156694"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
