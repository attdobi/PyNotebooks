{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Doc2vec Y/N classification </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "# gensim modules\n",
    "from __future__ import division\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence, TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "import re\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (12.0, 6.0) # set size of figures\"\n",
    "plt.rcParams.update({'font.size': 24})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get the data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(\"host=localhost dbname=qa user=attiladobi\")\n",
    "cur = conn.cursor()\n",
    "#connect to db and find open ended and yes/no question\n",
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'yes/no';\")\n",
    "Q_yn=cur.fetchall()\n",
    "cur.execute(\"SELECT question from qa WHERE questiontype  = 'open-ended';\")\n",
    "Q_oe=cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>clean sentences and create tagged docs for training </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_line(sentence):\n",
    "    '''Splits sentence if punctuation is identified. Returns a list of list of words for each sentence'''\n",
    "    sentences=re.split(r\"(?<![0-9])[.?!;](?![0-9])\", sentence)\n",
    "    result= [re.findall(\"[a-z'.-0-9]+\", sent.lower()) for sent in sentences if \\\n",
    "            re.findall(\"[a-z'.-0-9]+\", sent.lower())!=[]]\n",
    "    if result==[]:\n",
    "        result=[['']]\n",
    "    return result\n",
    "stoplist = set('number for a an of or the and to in rt'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> two catigories.... yn (yes no) and oe (open ended). Split 50/50 for training and testing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qs_yn= [[word for word in process_line(sentence[0])[0] if word not in stoplist] for sentence in Q_yn]\n",
    "\n",
    "qs_oe= [[word for word in process_line(sentence[0])[0] if word not in stoplist] for sentence in Q_oe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=qs_yn+qs_oe\n",
    "labels=np.hstack((ones(len(qs_yn)),zeros(len(qs_oe)))) #Label yn=1 and oe=0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,labels, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> build docs and lebel the two categories </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs=[]\n",
    "label_MAP={1:'YN_',0:'OE_'}\n",
    "\n",
    "for i,(words,label) in enumerate(zip(X_train, y_train)):\n",
    "    docs.append(TaggedDocument(words,[label_MAP[label]+str(i)]))\n",
    "    \n",
    "##probably a more elegent solution. but it gets the job done... each doc is tagged with \"Label_index\"\n",
    "\n",
    "#label='OE_'\n",
    "#for i,words in enumerate(qs_oe):\n",
    "#    docs.append(TaggedDocument(words,[label+str(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> train a doc2vec model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17454901"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Doc2Vec(min_count=2, window=20, size=100, sample=1e-4, negative=2, workers=4)\n",
    "#adjust the window sizze to match the typical number of words per doc\n",
    "model.build_vocab(docs)\n",
    "model.train(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['what', 'is', 'length', 'cord'], tags=['OE_0']),\n",
       " TaggedDocument(words=['i', 'am', 'size', '0', 'every', 'pair', 'leggings', 'i', 'get', 'sag', 'behind', 'knee', 'under', 'my', 'butt', 'will', 'these', 'sag'], tags=['YN_1']),\n",
       " TaggedDocument(words=['this', 'product', 'was', '9', 'two', 'days', 'ago'], tags=['OE_2']),\n",
       " TaggedDocument(words=['are', 'two', 'loop', 'handles', 'any', 'advantage', 'over', 'one', 'long', 'handle'], tags=['OE_3']),\n",
       " TaggedDocument(words=['what', 'is', 'duameter', 'base'], tags=['OE_4']),\n",
       " TaggedDocument(words=['i', 'have', \"'\", 'ford', 'f-', '0.'], tags=['OE_5']),\n",
       " TaggedDocument(words=['what', 'type', 'seal', 'does', 'this', 'box', 'have'], tags=['OE_6']),\n",
       " TaggedDocument(words=['what', 'percentage', 'hy', 'peroxide'], tags=['OE_7']),\n",
       " TaggedDocument(words=['anti-aging', 'property', 'is', \"denon's\", 'akdl', 'dedicated', 'link', 'cable', 'right', 'me'], tags=['OE_8']),\n",
       " TaggedDocument(words=['this', 'product', 'is', 'supposed', 'have', 'very', 'strong', 'odor'], tags=['YN_9'])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> save or load </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('/home/ubuntu/TallLabs/models/Rmodel_Doc2vec_cell_asin_title')\n",
    "#model=Doc2Vec.load('/home/ubuntu/TallLabs/models/Rmodel_Doc2vec_cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> before doing classification... it might be easier to see which vecrots are the most similar </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OE_567923', 0.7573308944702148),\n",
       " ('OE_60314', 0.746245265007019),\n",
       " ('OE_610076', 0.7441090941429138),\n",
       " ('OE_557712', 0.7434462308883667),\n",
       " ('OE_414245', 0.7371196150779724),\n",
       " ('OE_491108', 0.7297719717025757),\n",
       " ('OE_371811', 0.7229807376861572),\n",
       " ('OE_312769', 0.7211353778839111),\n",
       " ('OE_619637', 0.7203280925750732),\n",
       " ('OE_12538', 0.7190041542053223)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=model.infer_vector('what color is it'.lower().split()) #other params: ,alpha=0,steps=1 (steps is the learning rate)\n",
    "model.docvecs.most_similar([v],topn=10)\n",
    "#you can also find the most similar onces with a given tag: model.docvecs.most_similar('YN_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> ... turns out the vast majoirty of the similar documents are OE (OE). I could just run a quick test with the teting set </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train logistic regresion classifer </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#setup training for Y/N questions. we have to convert words to doc vector\n",
    "train_arrays=[]\n",
    "\n",
    "for i,label in enumerate(y_train):\n",
    "    train_arrays.append(model.docvecs[label_MAP[label]+str(i)])\n",
    "\n",
    "##can access each one with the index using: model.docvecs[i] and tags with odel.docvecs.doctags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_arrays, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test (will have to convert the array of words into a vector)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_arrays=[]\n",
    "\n",
    "for words in X_test:\n",
    "    test_arrays.append(model.infer_vector(words,alpha=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51501874565409067"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_arrays, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> lol this sucks, might do better with only a few key words or a smaller window :)</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['does', 'it', 'fit', 'satellite', 'p', 't-a']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
